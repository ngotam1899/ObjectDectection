{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop  :  87.32234239578247  :  [306, 238, 390, 284]\n",
      "--------------------------------\n",
      "laptop  :  96.8629777431488  :  [121, 209, 258, 293]\n",
      "--------------------------------\n",
      "laptop  :  98.63016605377197  :  [279, 321, 401, 425]\n",
      "--------------------------------\n",
      "laptop  :  99.785715341568  :  [451, 204, 579, 285]\n",
      "--------------------------------\n",
      "bed  :  94.02391910552979  :  [23, 205, 708, 553]\n",
      "--------------------------------\n",
      "apple  :  48.03135395050049  :  [527, 343, 557, 364]\n",
      "--------------------------------\n",
      "cup  :  34.099119901657104  :  [462, 347, 496, 379]\n",
      "--------------------------------\n",
      "cup  :  44.65084373950958  :  [582, 342, 618, 386]\n",
      "--------------------------------\n",
      "person  :  57.70223140716553  :  [27, 311, 341, 437]\n",
      "--------------------------------\n",
      "person  :  85.26120781898499  :  [304, 173, 387, 253]\n",
      "--------------------------------\n",
      "person  :  96.33604288101196  :  [415, 130, 538, 266]\n",
      "--------------------------------\n",
      "person  :  96.95256352424622  :  [174, 108, 278, 269]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"image2.jpg\"), \n",
    "                                             output_image_path=os.path.join(execution_path , \"image2newYolo.jpg\"), \n",
    "                                             minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nhận xét mô hình YOLOv3\n",
    "#Mô hình nhận diện được tổng cộng 12 đối tượng có trong hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\keras_retinanet\\backend\\tensorflow_backend.py:22: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\keras_retinanet\\backend\\tensorflow_backend.py:46: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "apple  :  35.70195436477661  :  [528, 345, 556, 364]\n",
      "--------------------------------\n",
      "apple  :  38.37689459323883  :  [506, 347, 581, 390]\n",
      "--------------------------------\n",
      "bowl  :  49.61661994457245  :  [503, 346, 583, 404]\n",
      "--------------------------------\n",
      "sandwich  :  34.04081165790558  :  [444, 373, 518, 410]\n",
      "--------------------------------\n",
      "bowl  :  36.917150020599365  :  [511, 377, 580, 409]\n",
      "--------------------------------\n",
      "person  :  91.94689989089966  :  [166, 106, 282, 273]\n",
      "--------------------------------\n",
      "person  :  73.61016273498535  :  [304, 169, 391, 255]\n",
      "--------------------------------\n",
      "person  :  38.81053924560547  :  [141, 172, 264, 283]\n",
      "--------------------------------\n",
      "laptop  :  40.59029817581177  :  [424, 168, 580, 278]\n",
      "--------------------------------\n",
      "laptop  :  90.24317264556885  :  [454, 204, 572, 281]\n",
      "--------------------------------\n",
      "laptop  :  73.688143491745  :  [125, 210, 253, 290]\n",
      "--------------------------------\n",
      "person  :  36.05002760887146  :  [229, 303, 345, 422]\n",
      "--------------------------------\n",
      "laptop  :  95.16398310661316  :  [269, 322, 406, 427]\n",
      "--------------------------------\n",
      "person  :  30.758321285247803  :  [19, 382, 164, 443]\n",
      "--------------------------------\n",
      "person  :  87.10319399833679  :  [432, 126, 581, 279]\n",
      "--------------------------------\n",
      "person  :  35.90748906135559  :  [72, 304, 318, 446]\n",
      "--------------------------------\n",
      "bed  :  48.27505946159363  :  [3, 242, 727, 495]\n",
      "--------------------------------\n",
      "dining table  :  43.09733211994171  :  [27, 249, 729, 515]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"image2.jpg\"), \n",
    "                                             output_image_path=os.path.join(execution_path , \"image2newRestina.jpg\"), \n",
    "                                             minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nhận xét mô hình RetinaNet\n",
    "#Mô hình nhận diện được tổng cộng 18 đối tượng có trong hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop  :  30.24056851863861  :  [305, 241, 387, 283]\n",
      "--------------------------------\n",
      "donut  :  54.28292155265808  :  [15, 379, 130, 438]\n",
      "--------------------------------\n",
      "person  :  58.40643048286438  :  [170, 104, 285, 296]\n",
      "--------------------------------\n",
      "person  :  62.5121533870697  :  [412, 120, 567, 282]\n",
      "--------------------------------\n",
      "person  :  84.35085415840149  :  [307, 169, 384, 256]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo-tiny.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"image2.jpg\"), \n",
    "                                             output_image_path=os.path.join(execution_path , \"image2newTinyYolo.jpg\"), \n",
    "                                             minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nhận xét mô hình TinyYOLOv3\n",
    "#Mô hình nhận diện được tổng cộng 5 đối tượng có trong hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog  :  91.02075695991516  :  [397, 312, 447, 433]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\dog-1.jpg\n",
      "--------------------------------\n",
      "cat  :  32.45977759361267  :  [391, 307, 444, 438]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\cat-2.jpg\n",
      "--------------------------------\n",
      "motorcycle  :  94.00216937065125  :  [266, 191, 345, 305]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\motorcycle-3.jpg\n",
      "--------------------------------\n",
      "car  :  98.45845699310303  :  [190, 141, 369, 288]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\car-4.jpg\n",
      "--------------------------------\n",
      "bicycle  :  37.193477153778076  :  [124, 241, 202, 387]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\bicycle-5.jpg\n",
      "--------------------------------\n",
      "person  :  66.52774214744568  :  [458, 146, 511, 267]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\person-6.jpg\n",
      "--------------------------------\n",
      "person  :  97.79707193374634  :  [11, 106, 63, 246]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\person-7.jpg\n",
      "--------------------------------\n",
      "person  :  98.00113439559937  :  [602, 134, 638, 213]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\person-8.jpg\n",
      "--------------------------------\n",
      "person  :  99.6942400932312  :  [539, 105, 578, 223]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\person-9.jpg\n",
      "--------------------------------\n",
      "person  :  99.79894757270813  :  [157, 135, 248, 386]\n",
      "Object's image saved in C:\\Users\\ngota\\image3new.jpg-objects\\person-10.jpg\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "detections, objects_path = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"image3.jpg\"), \n",
    "                                                           output_image_path=os.path.join(execution_path , \"image3new.jpg\"), \n",
    "                                                           minimum_percentage_probability=30,  \n",
    "                                                           extract_detected_objects=True)\n",
    "\n",
    "for eachObject, eachObjectPath in zip(detections, objects_path):\n",
    "    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"Object's image saved in \" + eachObjectPath)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
